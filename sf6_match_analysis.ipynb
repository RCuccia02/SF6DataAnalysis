{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2a92e2",
   "metadata": {},
   "source": [
    "# Street Fighter 6 Ranked Match Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Street Fighter 6 is a 2023 fighting game developed and published by Capcom, where characters engage in combat, aiming to deplete the opponent's health bar.\n",
    "\n",
    "This project aims to obtain insight about the current state of the game and players' performance by analyzing the results of the matches played in the game. Particularly, we will focus on the following aspects:\n",
    "- **Statistical analysis**: We will analyze the data distribution to understand the characteristics of the dataset.\n",
    "\n",
    "- **Characters performance**: We will analyze the performance of each character in the game, to find out which characters are most popular by players with different ranks.\n",
    "\n",
    "- **Player performance**: We will analyze the players' performance in the game, focusing on how the opponent's rank affects the player's performance.\n",
    "\n",
    "- **Matchup analysis**: We will analyze the matchups between characters to better understand how the characters perform against each other.\n",
    "\n",
    "- **Character Variety**: We will analyze the variety of characters used by a single player in their matches, focusing on how the number of characters used affects the player's performance.\n",
    "\n",
    "- **Outcome prediction**: We will build a machine learning model to predict the outcome of a match based on the players' ranks and characters used.\n",
    "\n",
    "Answering these questions will provide valuable insights into the game and its players, helping to understand the current state of the game and how players perform in it. This analysis can also help players improve their performance by understanding the factors that affect their performance in the game.\n",
    "\n",
    "## Data\n",
    "The dataset used in this project is a collection of match results from Street fighter 6, which includes information about the players, their ranks, characters used, and match outcomes. The dataset is available on Kaggle and can be accessed [here](https://www.kaggle.com/datasets/jlaw2013/street-fighter-6-ranked-matches-cleaned-up). \n",
    "The dataset contains a total of 1,196,670 rows and 9 columns, with each row representing a match between two players. The dataset includes matches played in ranked mode, which is a competitive mode where players are matched against others of similar skill level. It includes matches played between players of different ranks and characters, collected from the top players in the world by rank.\n",
    "\n",
    "The dataset contains the following variables:\n",
    "\n",
    "| Variable | Description | Data Type |\n",
    "|--------|-------------|-----------|\n",
    "| replay_id | Unique identifier for each match | string |\n",
    "| p1_id | Unique identifier for player 1 | int |\n",
    "| p1_mr | Rank of player 1 | int |\n",
    "| p1_char | Character used by player 1 | string |\n",
    "| p2_id | Unique identifier for player 2 | int |\n",
    "| p2_mr | Rank of player 2 | int |\n",
    "| p2_char | Character used by player 2 | string |\n",
    "| p1_result | Result of player 1 (win/loss) | boolean |\n",
    "| p2_result | Result of player 2 (win/loss) | boolean |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a16694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "print(\"Total number of matches:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc741d8",
   "metadata": {},
   "source": [
    "### Note on the ranking system\n",
    "The ranking system in Street Fighter 6 is based on LP (Ladder Points), which is a numerical representation of a player's skill level. Players earn 50 LP by winning matches and lose 40 LP by losing matches, thus climbing through the ranks, where the last rank is Master. However, the ranking system for Master players is different, based on the MR (Master Rate) system, where points are calculated based on the difference between the player's MR and the MR of the opponent. The MR system is designed to ensure that players are matched against opponents of similar skill level, providing a fair and competitive experience.\n",
    "The column `p1_mr` and `p2_mr` in the dataset represent the Master Rate of player 1 and 2, respectively. Players with a MR of 0 could possibly be in any rank below Master, but the dataset does not provide information about the exact rank of these players. To grant a better understanding of the analysis of this project, we will not consider the matches where both players have a MR of 0, as we cannot determine the rank of these players.\n",
    "\n",
    "Also, note that every character played by a player have a unique MR value, which means that a player can have different MR values for different characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['p1_mr'] > 0) & (df['p2_mr'] > 0)]\n",
    "print(\"Total number of matches with both players having MR > 0:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f1e90",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Statistical analysis\n",
    "In this section, we will analyze the distribution of the dataset. We will analyze frequency and measure central tendency, dispersion, and shape of the data, to understand how MR is distributed in the dataset.\n",
    "We will also show the distribution of the characters used by players in the dataset, to understand which characters are most popular among players.\n",
    "\n",
    "First we need to join the p1 and p2 columns to create a single dataframe with all the information about the players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p1 = df[['replay_id', 'p1_id', 'p1_mr', 'p1_char', 'p1_result']].copy()\n",
    "df_p1.columns = ['replay_id', 'player_id', 'mr', 'char', 'result']\n",
    "\n",
    "df_p2 = df[['replay_id', 'p2_id', 'p2_mr', 'p2_char', 'p2_result']].copy()\n",
    "df_p2.columns = ['replay_id', 'player_id', 'mr', 'char', 'result']\n",
    "\n",
    "df_long = pd.concat([df_p1, df_p2])\n",
    "\n",
    "df_long.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf8fd0",
   "metadata": {},
   "source": [
    "#### Master Rate distribution\n",
    "Our first step is to analyze the distribution of the Master Rate (MR) of the players in the dataset. We will plot a histogram to visualize the distribution of MR values, and calculate some statistics to understand the central tendency and dispersion of the data.\n",
    "\n",
    "We are going to define a new distribution, `average_mr_per_player`, which minimizes the influence of fluctuations in the MR between matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mr_per_player = df_long.groupby('player_id')['mr'].mean().reset_index().floordiv(1).astype(int)\n",
    "avg_mr_per_player.columns = ['player_id', 'average_mr']\n",
    "avg_mr_per_player.info()\n",
    "display(avg_mr_per_player.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732046ba",
   "metadata": {},
   "source": [
    "##### Central tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97facc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "# Plotting the distribution of MR\n",
    "axes[0].hist(df_long['mr'], color='green', bins=80, alpha=0.7)\n",
    "axes[0].set_title('Distribution of Master Rate (MR)')\n",
    "axes[0].set_xlabel('Master Rate (MR)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "# Plotting the distribution of average MR per player\n",
    "axes[1].hist(avg_mr_per_player['average_mr'], color='blue', bins=80, alpha=0.7)\n",
    "axes[1].set_title('Distribution of Average Master Rate (MR) per Player')\n",
    "axes[1].set_xlabel('Average Master Rate (MR)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fec95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print mean and median and mode of MR\n",
    "mr_mean = df_long['mr'].mean().round(0)\n",
    "mr_median = df_long['mr'].median()\n",
    "mr_mode = df_long['mr'].mode()[0]\n",
    "\n",
    "\n",
    "# print mean and median and mode of average MR\n",
    "avg_mr_mean = avg_mr_per_player['average_mr'].mean().round(0)\n",
    "avg_mr_median = avg_mr_per_player['average_mr'].median()\n",
    "avg_mr_mode = avg_mr_per_player['average_mr'].mode()[0]\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "    'Global MR': [mr_mean, mr_median, mr_mode],\n",
    "    'Avg MR': [avg_mr_mean, avg_mr_median, avg_mr_mode]\n",
    "})\n",
    "\n",
    "display(table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc217e",
   "metadata": {},
   "source": [
    "The table above shows the difference between considering the MR of the player in every match played and the average MR of the player. We can see that median and mode are significantly lower when we consider the average MR of the player, which is a more accurate representation of the player's skill level. This is because the average MR doesn't take into account the outliers in the dataset, which are a representation of one time peaks and lows in the player's performance, and thus are not a good representation of the player's skill level. The average MR is a better representation of the player's skill level.\n",
    "\n",
    "The mean is also lower. This is because usually players in a lower MR are less consistent and have a higher variance in their performance, which leads to a lower mean MR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5551afa2",
   "metadata": {},
   "source": [
    "##### Dispersion\n",
    "\n",
    "To better understand the differences between the two plots, we will also plot the ECDF (Empirical Cumulative Distribution Function) of the MR values. The ECDF shows the proportion of data points that are less than or equal to a given value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dcffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_ecdf = df_long['mr'].value_counts(normalize=True).sort_index().cumsum()\n",
    "\n",
    "# ECDF per il Master Rate medio per giocatore\n",
    "avg_mr_ecdf = avg_mr_per_player['average_mr'].value_counts(normalize=True).sort_index().cumsum()\n",
    "# Creazione del grafico\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(mr_ecdf.index, mr_ecdf.values, label='Global MR', linestyle='--', color='green', alpha=0.7)\n",
    "plt.plot(avg_mr_ecdf.index, avg_mr_ecdf.values, label='Avg MR per Player', linestyle='--', color='blue', alpha=0.7)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Master Rate (MR)\")\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"ECDF - MR Distribution Comparison\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "mr_max = df_long['mr'].max()\n",
    "mr_min = df_long['mr'].min()\n",
    "avg_mr_max = avg_mr_per_player['average_mr'].max()\n",
    "avg_mr_min = avg_mr_per_player['average_mr'].min()\n",
    "mr_std = df_long['mr'].std()\n",
    "mr_var = df_long['mr'].var()\n",
    "avg_mr_std = avg_mr_per_player['average_mr'].std()\n",
    "avg_mr_var = avg_mr_per_player['average_mr'].var()\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    'Statistic': ['Max', 'Min', 'Range', 'Std', 'Var'],\n",
    "    'Global MR': [mr_max, mr_min, mr_max - mr_min, mr_std, mr_var],\n",
    "    'Avg MR': [avg_mr_max, avg_mr_min, avg_mr_max - avg_mr_min, avg_mr_std, avg_mr_var]\n",
    "})\n",
    "display(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9384768",
   "metadata": {},
   "source": [
    "As we can see, both distributions have values that concentrate around the mean, which means that the standard deviation is small, and the data is not very dispersed. This could be due to the fact that players promoted to Master have an initial assigned MR of 1500, and a lot of players try different characters after reaching this rank. Further on this anlaysis we will analyze the Average MR only, which is a better representation of the player's skill level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campionamento\n",
    "df_sample = avg_mr_per_player.copy()\n",
    "df_sample['y'] = range(len(df_sample))\n",
    "df_sample = df_sample.sample(int(len(avg_mr_per_player)/20), random_state=66)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(df_sample['y'], df_sample['average_mr'], color='blue', label='Avg MR', alpha=0.5)\n",
    "plt.axhline(avg_mr_mean, color='black', linestyle='--', label='Mean Avg MR')\n",
    "\n",
    "for _, row in df_sample.iterrows():\n",
    "    plt.plot([row['y'], row['y']], [row['average_mr'], avg_mr_mean], color='red', linewidth=0.8, alpha=0.4)\n",
    "\n",
    "plt.title(f\"Variance: {avg_mr_var:.3f}\")\n",
    "plt.xlabel(\"Player index (sampled)\")\n",
    "plt.ylabel(\"average_mr\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ce0ee",
   "metadata": {},
   "source": [
    "The plot above shows us that the majority of players have a MR value close to the mean, which is between 1400 and 1600 and the number of outliers, compared to the rest of the data, is low. It is important to note that the plot shows only a sample of the data because the dataset is too large to plot all the data points. The sample is representative of the data, as it contains a random sample of 5% of the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f2080",
   "metadata": {},
   "source": [
    "##### Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36843a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mr_per_player['average_mr'].plot.density(color='blue', label='Avg MR', alpha=0.7)\n",
    "plt.axvline(avg_mr_mean, color='lightBlue', linestyle='--', label='Avg MR Mean')\n",
    "plt.xlim(avg_mr_min, avg_mr_max)\n",
    "plt.title('Density Plot of Avg MR')\n",
    "plt.xlabel('Master Rate (MR)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1468047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness average MR\n",
    "avg_mr_sk = avg_mr_per_player['average_mr'].skew()\n",
    "# kurtosis average MR\n",
    "avg_mr_kur = avg_mr_per_player['average_mr'].kurtosis()\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    'Statistic': ['Skewness', 'Kurtosis'],\n",
    "    'Avg MR': [avg_mr_sk, avg_mr_kur]\n",
    "})\n",
    "display(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543538d0",
   "metadata": {},
   "source": [
    "From the plot above we can discuss about the distribution's skewness and kurtosis values. The skewness value is 0.09, which indicates that the distribution is slightly positively skewed. This means that there are more players with lower MR values than higher MR values. The kurtosis value is 1.73, which indicates that the distribution is leptokurtic, meaning that the distribution has a higher peak than a normal distribution. This means that there are more players with MR values close to the mean than in a normal distribution, which is consistent with the plot above. This could also indicate the presence of outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "avg_mr_z = zscore(avg_mr_per_player['average_mr'])\n",
    "avg_mr_z = pd.Series(avg_mr_z, index=avg_mr_per_player.index)\n",
    "avg_mr_z.plot.density(color='blue', label='Avg MR Z-Score', alpha=0.7)\n",
    "\n",
    "avg_mr_min_z = avg_mr_z.min()\n",
    "avg_mr_max_z = avg_mr_z.max()\n",
    "\n",
    "plt.axvline(3, color='red', linestyle='--', label='Z = +3')\n",
    "plt.axvline(-3, color='red', linestyle='--', label='Z = -3')\n",
    "plt.xlim(avg_mr_min_z, avg_mr_max_z)\n",
    "plt.title('Density Plot of Z-Score')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Filtra gli outlier: z-score > 3 o < -3\n",
    "outlier_mask = np.abs(avg_mr_z) > 3\n",
    "\n",
    "# Calcola percentuale\n",
    "outlier_percent = (outlier_mask.sum() / len(avg_mr_z)) * 100\n",
    "print(f\"Outlier ±3 z-score: {outlier_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c72ed",
   "metadata": {},
   "source": [
    "Our suspection is confirmed by looking at the Z-score values of the MR values. A Z-score outside the range of -3 to 3 indicates that the value is an outlier. The plot above shows that there are a few players with MR values outside this range. Since the outliers percentage is low, we can still consider them in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e451d",
   "metadata": {},
   "source": [
    "#### Character usage distribution\n",
    "This section will analyze the distribution of characters used by players in the dataset. To better understand the distribution, we are considering the most played character by each player as his main, and the rest of the characters as his secondaries.\n",
    "The following bar plot visualizes the distribution of characters used by players, showing the usage percentage of each character divided into mains and secondaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcola personaggi main e secondari per ogni giocatore\n",
    "df_most_used = (\n",
    "    df_long.groupby(['player_id', 'char'])\n",
    "    .agg(mr=('mr', 'mean'), matches=('replay_id', 'count'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Main = personaggio con più match per ogni player\n",
    "df_main = df_most_used.loc[df_most_used.groupby('player_id')['matches'].idxmax()]\n",
    "\n",
    "# Secondary = tutti gli altri\n",
    "df_secondary = df_most_used[~df_most_used.index.isin(df_main.index)]\n",
    "\n",
    "# Conteggi\n",
    "main_counts = df_main['char'].value_counts()\n",
    "secondary_counts = df_secondary['char'].value_counts()\n",
    "\n",
    "# Unione e riempimento zeri\n",
    "all_chars = main_counts.index.union(secondary_counts.index)\n",
    "main_counts = main_counts.reindex(all_chars, fill_value=0)\n",
    "secondary_counts = secondary_counts.reindex(all_chars, fill_value=0)\n",
    "\n",
    "# Totale e percentuali\n",
    "total_counts = main_counts + secondary_counts\n",
    "total_percent = total_counts / total_counts.sum() * 100\n",
    "main_percent = main_counts / total_counts.sum() * 100\n",
    "\n",
    "# Ordina per percentuale totale decrescente\n",
    "sorted_chars = total_percent.sort_values(ascending=False).index\n",
    "main_counts = main_counts[sorted_chars]\n",
    "secondary_counts = secondary_counts[sorted_chars]\n",
    "main_percent = main_percent[sorted_chars]\n",
    "total_percent = total_percent[sorted_chars]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "ax.bar(sorted_chars, main_counts, label='Main', color='blue', alpha=0.7)\n",
    "ax.bar(sorted_chars, secondary_counts, bottom=main_counts, label='Secondary', color='orange', alpha=0.7)\n",
    "\n",
    "# Percentuali\n",
    "for i, (m, s, mp, tp) in enumerate(zip(main_counts, secondary_counts, main_percent, total_percent)):\n",
    "    if m > 0:\n",
    "        ax.text(i, m/2, f'{mp:.1f}%', ha='center', va='center', fontsize=9)\n",
    "    ax.text(i, m + s + 0.5, f'{tp:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Decorazioni\n",
    "ax.set_title('Character Usage (Main and Secondary)')\n",
    "ax.set_xlabel('Character')\n",
    "ax.set_ylabel('Number of Players')\n",
    "ax.set_xticks(range(len(sorted_chars)))\n",
    "ax.set_xticklabels(sorted_chars, rotation=70)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3cc6a",
   "metadata": {},
   "source": [
    "As we can see, the most used character is \"Mai\" with 13.2% of the total matches, followed by \"Akuma\" with 8%, with a large difference between them. From the second to the last character, the difference is small, with the last character being \"Random\" (as a random selected character) with 0.2% of the total matches. This is probably due to the fact that \"Mai\" is a new character in the game, released in Feb 5, 2025, and this dataset was collected in March 2025.\n",
    "\n",
    "We can see that the most used characters besides \"Mai\" are \"Akuma\", \"Ken\", \"Ryu\" and \"Luke\". These characters are popular among players, because they share the same playstyle as \"shotos\", which are known to rely on the very fundamental aspects of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd342c",
   "metadata": {},
   "source": [
    "### Character performance based on Rank\n",
    "In this section we will analyze the performance of each character based on the rank of the players using that character. Since players can use characters different from their main (which usually has the highest MR), for each player we are only going to consider the most used character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a593e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepara i dati: lista di array dei rank per ogni personaggio\n",
    "chars = df_main['char'].unique()\n",
    "data = [df_main[df_main['char'] == char]['mr'] for char in chars]\n",
    "\n",
    "# Crea il boxplot\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.boxplot(data, labels=chars, patch_artist=True)\n",
    "plt.title('Average MR Distribution for Characters (Main)')\n",
    "plt.xlabel('Character')\n",
    "plt.ylabel('MR')\n",
    "plt.xticks(rotation=70)\n",
    "\n",
    "\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e4547",
   "metadata": {},
   "source": [
    "We can see that all characters have a similar performance. This means that the game is balanced, and there are no characters that are significantly better than others. To better analyze the differences between characters, we will show the boxplots of the most and least used characters, which are \"Mai\" and \"Lily\", respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b709859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data for the first character\n",
    "\n",
    "data_minmax = data[11], data[6]\n",
    "chars_minmax = chars[11], chars[6]\n",
    "print(chars_minmax)\n",
    "\n",
    "# Crea il boxplot\n",
    "plt.figure(figsize=(5, 6))\n",
    "boxlot_data = plt.boxplot(data_minmax, labels=chars_minmax, patch_artist=True)\n",
    "plt.title('Average MR Distribution for Characters (Main)')\n",
    "plt.xlabel('Character')\n",
    "plt.ylabel('MR')\n",
    "plt.xticks(rotation=70)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384a801",
   "metadata": {},
   "source": [
    "We can see that the most used character, \"Mai\", has a shorter IQR, which means that the MR values are more concentrated around the median. This means that players using \"Mai\" have a more consistent performance than players using \"Lily\", who have a higher IQR, which means that the MR values are more dispersed. Also, many outliers can be found at the upper end of \"Mai\"'s boxplot, which means that there are players with a very high MR using this character. \n",
    "\n",
    "As we can see, \"Lily\" does not have a good performance at high level, which means that players using this character are not able to reach high ranks. This is probably due to the fact that \"Lily\" is a simple character with a simple gameplan, which makes it easier to play at low level, but harder to play at high level because of the opponent's matchup knowledge. This also reflects her low usage percentage shown before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f935c8",
   "metadata": {},
   "source": [
    "### Player Performance\n",
    "\n",
    "In this section we will determine if there is a correlation between the rank of the player and the opponent with respect to the match outcome. To achieve this, we will discretize the MR values into bins, and then we will do a chi-squared test.\n",
    "Seven bins were created, ranging from 0 to 2000, with a bin size of 100. Lowest and highest bins were merged to avoid having too many bins with few data points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd0a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins = [0, 1400, 1500, 1600, 1700, 1800, 1900, 2300]\n",
    "labels = [0, 1, 2, 3, 4, 5, 6] \n",
    "df_performance = df.copy()\n",
    "df_performance['p1_mr_bin'] = pd.cut(df_performance['p1_mr'], bins=bins, labels=labels, right=False)\n",
    "df_performance['p2_mr_bin'] = pd.cut(df_performance['p2_mr'], bins=bins, labels=labels, right=False)\n",
    "df_performance['bin_diff'] = (df_performance['p1_mr_bin'].astype(int) - df_performance['p2_mr_bin'].astype(int)).abs()\n",
    "\n",
    "df_performance['result'] = np.where(df_performance['p1_result'] & ~df_performance['p2_result'], 'p1', 'p2')\n",
    "\n",
    "df_performance['stronger'] = np.where(df_performance['p1_mr'] - df_performance['p2_mr'] > 0, 'p1', 'p2')\n",
    "\n",
    "df_performance['winner_is_stronger'] = np.where(df_performance['result'] == df_performance['stronger'], 1, 0)\n",
    "\n",
    "df_performance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe982c",
   "metadata": {},
   "source": [
    "Below is shown the contingency table of the MR bin difference and the match outcome. The table shows the number of matches played between players with different MR bins, and the number of wins for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08363a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "contingency_table = pd.crosstab(df_performance['bin_diff'], df_performance['winner_is_stronger'])\n",
    "contingency_table.columns = ['W is Stronger', 'W is Weaker']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(contingency_table, annot=True, fmt='d', cmap='YlGnBu', linewidths=0.5, cbar=True)\n",
    "\n",
    "\n",
    "plt.title('Contingency Table: P1 vs P2 Wins by Rank Difference')\n",
    "plt.xlabel('Match Result')\n",
    "plt.ylabel('Rank Difference (P1 - P2)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b87a92",
   "metadata": {},
   "source": [
    "Now we can proceed to do the chi-squared test. The null hypothesis is that there is no correlation between the MR bin difference and the match outcome. The alternative hypothesis is that there is a correlation between the MR bin difference and the match outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi² = {chi2:.2f}\")\n",
    "print(f\"p-value = {p:.4f}\")\n",
    "print(f\"Degrees of Freedom = {dof}\")\n",
    "contingency_table['total'] = contingency_table['W is Stronger'] + contingency_table['W is Weaker']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f8183",
   "metadata": {},
   "source": [
    "The Chi-squared value is 16431.35, which means that obsserved and expected values are significantly different. The p-value is 0.0, which means that we can reject the null hypothesis. We can state that there is a correlation between the MR bin difference and the match outcome. To get better evidence of this, we can also plot the proportion of wins for each MR bin difference. The plot below shows the probability of the highest MR player to win the match, based on the MR bin difference. The plot shows that the higher the MR bin difference, the higher the probability of winning for the player with the highest MR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec955d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcolo percentuali\n",
    "p_stronger_wins = contingency_table['W is Stronger'] / contingency_table['total']\n",
    "\n",
    "# Plot\n",
    "p_stronger_wins.plot(kind='bar', color='blue', edgecolor='black')\n",
    "plt.title('Chance of stronger player winning by rank difference')\n",
    "plt.ylabel('Chance of winning')\n",
    "plt.xlabel('Absolute difference in rank bins')\n",
    "plt.ylim(0, 1)\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', label='50%')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fa2af",
   "metadata": {},
   "source": [
    "From a player's perspective, this effect may feel less pronounced. In actual gameplay, players often attribute wins and losses to factors like matchup familiarity, mistakes, or mind games. Also, the game is known to be too volatile, allowing weakest players to win against the strongest However, the data shows that MR still plays a strong and measurable role. This suggests that player skill, as measured by MR, is a reliable predictor of match outcome, even if it doesn't always feel that way from inside the match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29bf86",
   "metadata": {},
   "source": [
    "#### Matchup Analysis\n",
    "In this section, we will analyze the matchups between characters to better understand how the characters perform against each other. We will create a matrix that shows the log-odds of each character winning against every other character. The log-odds is calculated as the logarithm of the ratio of the number of wins to the number of losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_odds(row):\n",
    "    a = row['char1_wins'] + 1\n",
    "    b = row['char2_wins'] + 1\n",
    "    return np.log(a / b)\n",
    "\n",
    "def count_matchup_stats(df):\n",
    "    matchup_stats = df.groupby(['char1', 'char2']).agg(\n",
    "        char1_wins=('char1_win', 'sum'),\n",
    "        char2_wins=('char2_win', 'sum')\n",
    "    ).reset_index()\n",
    "    matchup_stats['logodds'] = matchup_stats.apply(compute_log_odds, axis=1)\n",
    "\n",
    "    reversed_stats = matchup_stats.rename(columns={'char1': 'char2', 'char2': 'char1', 'char1_wins': 'char2_wins', 'char2_wins': 'char1_wins'}).copy()\n",
    "    reversed_stats['logodds'] = -reversed_stats['logodds']\n",
    "    return matchup_stats, reversed_stats\n",
    "\n",
    "def setup_matchup_stats(df, percentile_value=0):\n",
    "\n",
    "    df_matchups = df[\n",
    "        (df['p1_mr'] > percentile_value) & (df['p2_mr'] > percentile_value)\n",
    "    ][['p1_char', 'p2_char', 'p1_result', 'p2_result', 'p1_mr', 'p2_mr']].copy()\n",
    "    df_matchups = df_matchups[~df_matchups['p1_char'].isin(['Random']) & ~df_matchups['p2_char'].isin(['Random'])]\n",
    "\n",
    "    df_matchups['char1'] = df_matchups[['p1_char', 'p2_char']].min(axis=1)\n",
    "    df_matchups['char2'] = df_matchups[['p1_char', 'p2_char']].max(axis=1)\n",
    "\n",
    "    df_matchups['char1_win'] = np.where(df_matchups['p1_char'] == df_matchups['char1'], df_matchups['p1_result'], df_matchups['p2_result'])\n",
    "    df_matchups['char2_win'] = ~df_matchups['char1_win'] \n",
    "    return df_matchups\n",
    "\n",
    "def display_matchup_heatmap(full_stats):\n",
    "    # heatmap contingency table per log odds\n",
    "    contingency_table = pd.crosstab(full_stats['char1'], full_stats['char2'], values=full_stats['logodds'], aggfunc='mean')\n",
    "\n",
    "    plt.figure(figsize=(24, 16))\n",
    "    sns.heatmap(contingency_table, annot=True, fmt='.2f', cmap='bwr', linewidths=0.5, cbar=True, center=0, square=True)\n",
    "    plt.title('Log Odds Heatmap of Matchups')\n",
    "    plt.xlabel('Character 2')\n",
    "    plt.ylabel('Character 1')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add589c3",
   "metadata": {},
   "source": [
    "Below, the contingency table showing the log-odds of each character winning against every other character is displayed as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matchups = setup_matchup_stats(df)\n",
    "full_stats = pd.concat(count_matchup_stats(df_matchups), ignore_index=True)\n",
    "\n",
    "display_matchup_heatmap(full_stats)\n",
    "\n",
    "display(full_stats[(full_stats['char1'] != full_stats['char2'])].sort_values(by='logodds', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b6823",
   "metadata": {},
   "source": [
    "As we can see, the most unbalanced matchup is between \"Zangief\" and \"Dhaslim\", with a log-odds of 0.54. This values is small, which means that there is no significant advantage for either character. The log-odds values are generally small, which means that the matchups are balanced. This is a good sign for the game, as it means that the game is balanced and there are no characters that are overpowered.\n",
    "From a player's perspective, I would say that the data does not respect the reality. In fact, the matchup \"Dhalsim\" vs \"Zangief\" is considered one of the most unbalanced matchups in the game, with \"Zangief\" having a significant disadvantage over \"Dhaslim\". This is because \"Zangief\" is a grappler character, which means that he relies on getting close to the opponent to deal damage, while \"Dhaslim\" is a zoner character, which means that he relies on keeping the opponent at a distance to deal damage.\n",
    "\n",
    "For this reason, a better way to analyze the matchups is to consider the matches played by players with a higher MR, as those players are more skilled and are capable to maximize their character's potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_percentile = 97.5\n",
    "percentile_value = np.percentile(pd.concat([df['p1_mr'], df['p2_mr']]), mr_percentile)\n",
    "print(f\"Percentile value for MR > {mr_percentile}: {percentile_value}\")\n",
    "df_matchups = setup_matchup_stats(df, percentile_value)\n",
    "full_stats = pd.concat(count_matchup_stats(df_matchups), ignore_index=True)\n",
    "\n",
    "display_matchup_heatmap(full_stats)\n",
    "\n",
    "display(full_stats[(full_stats['char1'] != full_stats['char2'])].sort_values(by='logodds', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_stats[(full_stats['char1'] == 'Zangief') & (full_stats['char2'] == 'Dhalsim')])\n",
    "display(full_stats[(full_stats['char1'] == 'Dhalsim') & (full_stats['char2'] == 'Zangief')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465f2a49",
   "metadata": {},
   "source": [
    "As we thought, the log-odds value favors \"Dhalsim\" over \"Zangief\" when we consider the matches played by players with a higher MR. However, it is necessary to note that the sample size of the matches played by players with a higher MR is small, which means that the log-odds values may not be fully reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16947bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = np.arange(0, 100, 10)\n",
    "logodds_values = []\n",
    "\n",
    "for p in percentiles:\n",
    "    threshold = np.percentile(pd.concat([df['p1_mr'], df['p2_mr']]), p)\n",
    "\n",
    "    df_matchups = setup_matchup_stats(df, percentile_value=threshold)\n",
    "    matchup_stats, reversed_stats = count_matchup_stats(df_matchups)\n",
    "    full_stats = pd.concat([matchup_stats, reversed_stats], ignore_index=True)\n",
    "\n",
    "    row = full_stats[\n",
    "        ((full_stats['char1'] == 'Zangief') & (full_stats['char2'] == 'Dhalsim'))\n",
    "    ]\n",
    "\n",
    "    if row.empty:\n",
    "        logodds_values.append(np.nan)\n",
    "    else:\n",
    "        logodds_values.append(row['logodds'].values[0])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(percentiles, logodds_values, marker='o', label='Zangief vs Dhalsim')\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.xlabel(\"Percentile minimo MR\")\n",
    "plt.ylabel(\"Log-Odds\")\n",
    "plt.title(\"Zangief vs Dhalsim: Log-Odds al variare del percentile di MR\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad00f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MR value for percentile > {mr_percentile}: {percentile_value}\")\n",
    "display(df[\n",
    "    ((df['p1_char'] == 'Zangief') & (df['p2_char'] == 'Dhalsim') | \n",
    "    (df['p1_char'] == 'Dhalsim') & (df['p2_char'] == 'Zangief')) & \n",
    "    (df['p1_mr'] > percentile_value) & (df['p2_mr'] > percentile_value)])\n",
    "\n",
    "# count number of different players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b65d6",
   "metadata": {},
   "source": [
    "#### Character Variety\n",
    "In this section, we will analyze the variety of characters used by a single player in their matches, focusing on how the number of characters used affects the player's performance. The method used is the pearson correlation coefficient, which measures the linear correlation between two variables. The closer the coefficient is to 1 or -1, the stronger the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from df_long, count number of different characters grouped by player_id, also calculate mean mr\n",
    "char_counts = df_long.groupby('player_id')['char'].nunique().reset_index()\n",
    "char_counts.columns = ['player_id', 'num_characters']\n",
    "char_counts['mean_mr'] = df_long.groupby('player_id')['mr'].mean().reset_index(drop=True)\n",
    "\n",
    "display(char_counts.head())\n",
    "\n",
    "corr = char_counts[\"mean_mr\"].corr(char_counts[\"num_characters\"])\n",
    "\n",
    "print(f\"Correlation between mean MR and number of characters used: {corr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349e3f1",
   "metadata": {},
   "source": [
    "A correlation coefficient of 0.22 indicates a weak positive correlation between the mean MR and the number of characters used by a player. This means that players who use more characters tend to have a higher average MR, but the correlation is not strong enough to draw definitive conclusions. Below the correlation is shown through a scatter plot with a linear regression line and a Lowess smoothing line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(\n",
    "    data=char_counts,\n",
    "    x=\"num_characters\",\n",
    "    y=\"mean_mr\",\n",
    "    s=30,\n",
    "    alpha=0.7,\n",
    "    color=\"blue\",\n",
    "    label=\"Player's Mean MR\"\n",
    ")\n",
    "\n",
    "# regression line for linear fit\n",
    "sns.regplot(\n",
    "    data=char_counts,\n",
    "    x=\"num_characters\",\n",
    "    y=\"mean_mr\",\n",
    "    scatter=False,\n",
    "    color=\"green\",\n",
    "    label=\"Linear fit (Pearson)\"\n",
    ")\n",
    "\n",
    "# Lowess smoothing line\n",
    "sns.regplot(\n",
    "    data=char_counts,\n",
    "    x=\"num_characters\",\n",
    "    y=\"mean_mr\",\n",
    "    scatter=False,\n",
    "    lowess=True,\n",
    "    color=\"red\",\n",
    "    label=\"Lowess smoothing (Spearman)\",\n",
    ")\n",
    "\n",
    "plt.title(\"Linear and Lowess Regression of Mean MR vs Number of Characters Used\")\n",
    "plt.xlabel(\"Number of Characters Used\")\n",
    "plt.ylabel(\"Mean MR\")\n",
    "plt.xticks(range(1, char_counts['num_characters'].max() + 1))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d9a24",
   "metadata": {},
   "source": [
    "The correlation coefficient is low, so we use a Lowess smoothing line to better visualize the correlation. The plot shows that there is a big difference between the players who use only one character and those who use two, but after that the difference is small. This could mean that players who use more characters have a better understanding of the game's mechanics and are able to adapt to different situations, but the correlation is not strong enough to draw definitive conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc4708",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "In this section, we will build a machine learning model to predict the outcome of a match based on the players' ranks and characters used. The model will be trained on the dataset and will be able to predict the outcome of a match based on the players' ranks and characters used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creazione di un set di tutti i personaggi unici\n",
    "all_chars = pd.concat([df['p1_char'], df['p2_char']]).unique()\n",
    "\n",
    "# Creazione di un dizionario che mappa ogni personaggio a un indice\n",
    "char_to_idx = {char: i for i, char in enumerate(all_chars)}\n",
    "\n",
    "# Aggiunta delle colonne con gli indici dei personaggi\n",
    "df['p1_char_idx'] = df['p1_char'].map(char_to_idx)\n",
    "df['p2_char_idx'] = df['p2_char'].map(char_to_idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08fbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# Creazione dei tensori per le feature numeriche (rank) e le feature categoriche (personaggi)\n",
    "X_mr = torch.tensor(df[['p1_mr', 'p2_mr']].values, dtype=torch.float32)\n",
    "X_p1_char = torch.tensor(df['p1_char_idx'].values, dtype=torch.long)\n",
    "X_p2_char = torch.tensor(df['p2_char_idx'].values, dtype=torch.long)\n",
    "y = torch.tensor(df['p1_result'].values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Creazione del dataset e suddivisione in training e test\n",
    "dataset = TensorDataset(X_mr, X_p1_char, X_p2_char, y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Creazione dei DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=7)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, num_workers=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LogisticCatModel(pl.LightningModule):\n",
    "    def __init__(self, num_chars, embed_dim=4):\n",
    "        super().__init__()\n",
    "        # Definizione degli embedding per i personaggi\n",
    "        self.p1_embed = nn.Embedding(num_chars, embed_dim)\n",
    "        self.p2_embed = nn.Embedding(num_chars, embed_dim)\n",
    "        \n",
    "        # Layer finale per la regressione logistica\n",
    "        self.linear = nn.Linear(2 + 2*embed_dim, 1)\n",
    "    \n",
    "    def forward(self, mr, p1_char, p2_char):\n",
    "        # Recupero degli embedding per i personaggi\n",
    "        p1_emb = self.p1_embed(p1_char)\n",
    "        p2_emb = self.p2_embed(p2_char)\n",
    "        # Concatenazione delle feature numeriche e degli embedding\n",
    "        x = torch.cat([mr, p1_emb, p2_emb], dim=1)\n",
    "        # Passaggio attraverso il layer finale con attivazione sigmoid\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        mr, p1_char, p2_char, y = batch\n",
    "        y_hat = self(mr, p1_char, p2_char)\n",
    "        loss = F.binary_cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        mr, p1_char, p2_char, y = batch\n",
    "        y_hat = self(mr, p1_char, p2_char)\n",
    "        loss = F.binary_cross_entropy(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f87855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del modello\n",
    "num_chars = len(all_chars)\n",
    "model = LogisticCatModel(num_chars=num_chars, embed_dim=4)\n",
    "\n",
    "# Creazione del trainer\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "\n",
    "# Addestramento del modello\n",
    "trainer.fit(model, train_loader, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
